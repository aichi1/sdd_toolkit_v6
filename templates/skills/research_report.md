# Phase {N}: {Phase Name}

> このテンプレートは research_report カテゴリ用です。
> プレースホルダー `{...}` を実際の値に置換してください。

## Objective
{このフェーズが生み出すものの明確な記述}

## Input Requirements
- docs/requirements.md（目的・スコープ・成功条件）
- docs/plan.md（Phase構成）
- {前フェーズの出力があれば記載}
- {外部情報源があれば記載}

## Output Specification
成果物: `outputs/phase-{N}/{ファイル名}.md`

### 必須セクション構成
成果物には以下のセクションを **この順序で** 含めること：

1. **TL;DR / エグゼクティブサマリー**（冒頭に配置、3-5行で結論を要約）
2. **比較軸の定義と選定理由**（なぜこの軸で比較するのか）
3. **各対象の詳細分析**（対象ごとにサブセクション）
4. **比較表**（全対象 x 全軸のマトリクス、Markdown表形式）
5. **不確実性・留意点**（データの限界、前提条件、注意事項を明記）
6. **結論と推奨**（比較結果に基づく推奨案）
7. **出典・参考文献**（情報源を一覧化、URLと取得日を含む）

## Quality Criteria
- [ ] TL;DR が冒頭にあり、結論を読むだけで要点が分かる
- [ ] 比較軸が明確に定義され、選定理由が説明されている
- [ ] 全データに出典（情報源、取得日）が明記されている
- [ ] 不確実性・留意点セクションがあり、データの限界が述べられている
- [ ] 比較表が全対象 x 全軸を網羅している
- [ ] docs/requirements.md の成功条件を全て満たしている

## Procedure
1. docs/ を読み、調査対象と評価軸を確認する
2. {前フェーズ出力があれば} 前フェーズのデータを読み込む
3. 各対象について情報を収集・整理する
4. 比較軸ごとに分析を実施する
5. 比較表を作成する（Markdown表形式）
6. 不確実性・留意点を洗い出して記載する
7. 結論と推奨を比較結果から導出する
8. TL;DR を最後に書く（結論確定後に要約するため）
9. 出典リストを整理する
10. outputs/phase-{N}/ に保存し .metadata.json を作成する

### 専門家エージェントの活用（該当する場合）
- **citations_researcher**: Step 9 の出典整理時に呼び出し、引用の網羅性と正確性を確認
- **domain_sme**: Step 4 の分析時に呼び出し、ドメイン固有の妥当性を確認
- **risk_reviewer**: Step 6 の不確実性洗い出し時に呼び出し

## Common Pitfalls
- TL;DR を書き忘れる → 必ず最後に冒頭へ追加
- 出典を後回しにして不明になる → 収集時に逐次記録
- 不確実性を省略する → 「確実に分かること」と「推測」を区別
- 比較表の軸が不均一 → 全対象に同じ軸を適用

## Examples
```markdown
# WebAssembly フレームワーク比較レポート

## TL;DR
Blazor が機能性・学習コストで優位。Yew は性能面で強いが学習コスト高。
コミュニティ規模では Blazor が圧倒的。推奨: Blazor（ただし性能要件が厳しい場合は Yew）。

## 比較軸と選定理由
| 軸 | 理由 |
|---|---|
| 機能性 | 実用レベルのアプリ構築に必要 |
| 性能 | ユーザー体験に直結 |
...
```
